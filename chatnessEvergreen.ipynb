{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Tjg7HVjr5sIfdXaFfDqdg_w5AeXblvcu",
      "authorship_tag": "ABX9TyPp/upOxUJnQqIIv8tdZs+V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walkerjian/dev/blob/main/chatnessEvergreen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Persistent AI Chat Companion in Colab\n",
        "\n",
        "This notebook lets you have an ongoing conversation with a powerful AI, powered by OpenAI's GPT models. Your chat history is automatically saved and loaded, allowing you to seamlessly continue where you left off!"
      ],
      "metadata": {
        "id": "-sHiR2X3_aDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install httpx==0.27.2 --force-reinstall"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BTxGRmrosx0j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "mykey=userdata.get('OPENAI_API_KEY')\n",
        "#print(mykey)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZxGX3-yWq9KQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PhPlxMlckdQ9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import auth\n",
        "\n",
        "# Authenticate user\n",
        "auth.authenticate_user()\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=mykey  # Replace with your API key\n",
        ")\n",
        "def load_conversation(file_path):\n",
        "    \"\"\"Load conversation history from a file.\"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            try:\n",
        "                print(\"Loading conversation from file...\")\n",
        "                print(file_path)\n",
        "                return json.load(file)\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"Conversation file is corrupted. Starting fresh.\")\n",
        "    return [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "\n",
        "def save_conversation(file_path, messages):\n",
        "    \"\"\"Save conversation history to a file.\"\"\"\n",
        "    with open(file_path, \"w\") as file:\n",
        "        json.dump(messages, file, indent=4)\n",
        "\n",
        "def continue_chat(messages, user_input, model=\"gpt-4\"):\n",
        "    \"\"\"Continue the chat by sending the conversation context and the new user input.\"\"\"\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    try:\n",
        "        # Create a chat completion\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=model,\n",
        "        )\n",
        "        # Extract the assistant's response\n",
        "        assistant_reply = chat_completion.choices[0].message.content\n",
        "        print(f\"\\nAssistant: {assistant_reply}\\n\")\n",
        "        # Append the assistant's reply to the conversation history\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "        return messages\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return messages\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File for conversation history\n",
        "filename = input(\"Enter the name of an existing conversation file to continue (or press Enter to start new): \").strip()\n",
        "\n",
        "if filename and os.path.exists(filename):\n",
        "    print(f\"Loading conversation from {filename}...\")\n",
        "    conversation = load_conversation(filename)\n",
        "else:\n",
        "    if filename:\n",
        "        print(f\"File '{filename}' not found. Starting a new conversation.\")\n",
        "    conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "    filename = input(\"Enter a filename to save this new conversation: \").strip()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECONtCRclA08",
        "outputId": "f829bf75-c5f4-4e43-b0fc-6c57854d7106"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name of an existing conversation file to continue (or press Enter to start new): spud.json\n",
            "Loading conversation from spud.json...\n",
            "Loading conversation from file...\n",
            "spud.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just copy and paste this cell to continue the chat!"
      ],
      "metadata": {
        "id": "aXoac2eO4_2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this cell for one shots, or repeatedly copy and paste it!"
      ],
      "metadata": {
        "id": "mIkRb9OR_ATx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user input\n",
        "user_message = input(\"You: \")\n",
        "\n",
        "# Continue the conversation\n",
        "conversation = continue_chat(conversation, user_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_2QZY0_u9Gy",
        "outputId": "a7f89b60-d55b-453a-9fb7-1dfb10914bb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: so how far into the maelstrom of vicious fishes have we got?\n",
            "\n",
            "Assistant: Well, it appears we have dived right in! We've navigated the choppy waters of unique recipe creation using fish, namely anchovies as our star ingredient. Along with our trusty companions, the spuds and cabbage, we've created a dish that can sail any sea.\n",
            "\n",
            "Just as the Maelstrom is an intense whirlpool that can throw any sailor off their course, sometimes the culinary world can feel the same. But fear not! With this bold and flavorful stir fry, you've weathered the storm.\n",
            "\n",
            "And remember, just like in the ocean, there's always more to explore in the world of 'vicious fishes.' So, should you want to continue this voyage and explore more daring and delicious dishes, feel free to ask!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use this cell to loop until ur done, son ..."
      ],
      "metadata": {
        "id": "BdvKB6uf_H9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (previous code) ...\n",
        "\n",
        "# Chat loop\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_message = input(\"You: \")\n",
        "\n",
        "    # Exit condition\n",
        "    if user_message.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # Continue the conversation\n",
        "    conversation = continue_chat(conversation, user_message)\n",
        "\n",
        "# Save the conversation before exiting\n",
        "save_conversation(filename, conversation)\n",
        "print(f\"Conversation saved to {filename}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdN0PLoz-Eza",
        "outputId": "84959828-4134-4a43-a959-40471d50ec9c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: choppy waters, chopped anchovies, i see what you did there even of you didnt :)\n",
            "\n",
            "Assistant: That was a great catch! I'm glad you enjoyed the wordplay. It's always wonderful to add a touch of humor and wit, especially when we're talking about something as fun and creative as cooking. If you have any more questions or need further assistance, feel free to ask. I'm here to help.\n",
            "\n",
            "You: lol, catch :))\n",
            "\n",
            "Assistant: I'm glad you \"caught\" that, too! Cooking and wordplay can both be a lot of \"fin.\" If you have any other questions or need assistance with anything else, don't hesitate to ask!\n",
            "\n",
            "\n",
            "You: too much, it needs a nap\n",
            "\n",
            "Assistant: Of course, take your time to relax and rejuvenate! Feel free to reach out to me whenever you need assistance next time. Enjoy your rest!\n",
            "\n",
            "You: exit\n",
            "Conversation saved to spud.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hIol_nqc-gaw"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}