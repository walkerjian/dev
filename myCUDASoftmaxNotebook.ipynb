{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walkerjian/dev/blob/main/myCUDASoftmaxNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unofficial [LeetArxiv](https://leetarxiv.substack.com/p/cuda-papers-day-1-online-softmax) implementation of the paper *Online Normalizer Calculation for Softmax* (Milakov & Gimelshein, 2018)\n",
        "\n",
        "\n",
        "Complete writeup and coding guide available [here](https://leetarxiv.substack.com/p/cuda-papers-day-1-online-softmax)\n",
        "\n",
        "LeetArxiv is a successor to Papers with Code after the latter shutdown.\n",
        "\n",
        "Here is [12 months of Perplexity](https://pplx.ai/murage-kibicho) Pro on us.\n",
        "\n",
        "Here’s [20 dollars to send money abroad](https://remit.ly/d4kssha1).\n",
        "\n",
        "Here are some [free gpu credits](https://runpod.io/?ref=0wy3bt8r) :)\n",
        "\n",
        "Here’s some [free Polymarket credits](https://polymarket.com/event/1-searched-person-on-google-this-year?tid=1764583364122).\n",
        "\n"
      ],
      "metadata": {
        "id": "g9el2aqjV7qR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper Summary\n",
        "\n",
        "The 2018 paper Online Normalizer Calculation for Softmax (Milakov & Gimelshein, 2018) addresses two shortcomings with the original softmax:\n",
        "\n",
        "1. The naive softmax suffers from underflow and overflow when inputs are extreme (Tianlong, 2025).\n",
        "\n",
        "2. The safer version of the naive softmax cannot run in parallel on GPU (Wangkuiyi, 2025)\n",
        "\n",
        "The authors use a pretty clever trick to calculate the online normalizer in one loop (Tianlong, 2025).\n",
        "\n",
        "Instead of first finding the maximum, the authors propose rescaling the accumulated sum whenever a new max is encountered."
      ],
      "metadata": {
        "id": "1uMaV7M6X8hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check CUDA Runtime"
      ],
      "metadata": {
        "id": "szRilkvZYCFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8Kmza1OElan",
        "outputId": "c17bbd37-c5c6-4362-da14-0dfc47b1b925"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Tue Dec  2 21:50:54 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install CUDA Cell Magic\n",
        "\n",
        "We tell Colab it's not Python using the\n",
        "`%%cuda -c \"-I /does/not/exist -arch=sm_75\"\n",
        "` syntax."
      ],
      "metadata": {
        "id": "-f-oj6HVYJEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXhLAONZEr7b",
        "outputId": "76bb9b7e-2fa4-48e4-e2e2-72d8d264d17f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpa_r60euo\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write CUDA Code\n",
        "\n",
        "We walk through each line of code in our article."
      ],
      "metadata": {
        "id": "owILwGulYVog"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQhi23JjEOS_",
        "outputId": "548b05f6-d296-46e4-ffe1-f7f5872384b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU softmax time: 0.195 ms\n",
            "CPU softmax time: 30.266 ms\n",
            "Max absolute error: 8.381903e-09\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda -c \"-I /does/not/exist -arch=sm_75\"\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define CEIL_DIV(x, y) ((x + y - 1) / (y))\n",
        "#define CUDA_CHECK(err) do { if(err != cudaSuccess) { \\\n",
        "\tprintf(\"CUDA Error: %s:%d, %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); exit(-1); }} while(0)\n",
        "\n",
        "__global__ void OnlineSoftmaxCUDA(size_t rows, size_t cols, float *input, float *output)\n",
        "{\n",
        "\t__shared__ float sharedMemory[1024];\n",
        "\tint warpSize = 32;\n",
        "\tint threadIndex = threadIdx.x;\n",
        "\tint matrixRowIndex = blockIdx.x;\n",
        "\n",
        "\t//Ensure threads are working on actual data\n",
        "\tif(matrixRowIndex >= rows){return;}\n",
        "\tfloat *inputRow  = input  + matrixRowIndex * cols;\n",
        "\tfloat *outputRow = output + matrixRowIndex * cols;\n",
        "\tfloat maximumValue   = -INFINITY;\n",
        "\tfloat sumOfExponents = 0.0f;\n",
        "\n",
        "\t//Each thread has its own max and sum\n",
        "\tfor(int i = threadIndex; i < cols; i += blockDim.x)\n",
        "\t{\n",
        "\t\tfloat x = inputRow[i];\n",
        "\t\tif(x > maximumValue)\n",
        "\t\t{\n",
        "\t\t\tsumOfExponents = sumOfExponents * expf(maximumValue - x) + 1.0f;\n",
        "\t\t\tmaximumValue   = x;\n",
        "\t\t}\n",
        "\t\telse\n",
        "\t\t{\n",
        "\t\t\tsumOfExponents += expf(x - maximumValue);\n",
        "\t\t}\n",
        "\t}\n",
        "\t__syncthreads();\n",
        "\n",
        "\t//Find warp level maximum\n",
        "\tfloat warpMax = maximumValue;\n",
        "\tfor(int offset = warpSize / 2; offset > 0; offset /= 2)\n",
        "\t{\n",
        "\t\twarpMax = fmaxf(warpMax, __shfl_down_sync(0xffffffff, warpMax, offset));\n",
        "\t}\n",
        "\t//Store warp's maximum in shared memory\n",
        "\tif(threadIndex % warpSize == 0)\n",
        "\t{\n",
        "\t\tsharedMemory[threadIndex / warpSize] = warpMax;\n",
        "\t}\n",
        "\t__syncthreads();\n",
        "\n",
        "\t//Find block level maximum\n",
        "\tif(threadIndex < warpSize)\n",
        "\t{\n",
        "\t\tint warpCount = CEIL_DIV(blockDim.x, warpSize);\n",
        "\t\tfloat v = (threadIndex < warpCount) ? sharedMemory[threadIndex] : -INFINITY;\n",
        "\t\tfor(int offset = warpSize / 2; offset > 0; offset /= 2){v = fmaxf(v, __shfl_down_sync(0xffffffff, v, offset));}\n",
        "\t\tif(threadIndex == 0){sharedMemory[0] = v;}\n",
        "\t}\n",
        "\t__syncthreads();\n",
        "\tfloat rowMaximum = sharedMemory[0];\n",
        "\t__syncthreads();\n",
        "\t// rescale sum\n",
        "\tfloat localSum = sumOfExponents * expf(maximumValue - rowMaximum);\n",
        "\n",
        "\tfloat warpSum = localSum;\n",
        "\tfor(int offset = warpSize / 2; offset > 0; offset /= 2)\n",
        "\t{\n",
        "\t\twarpSum += __shfl_down_sync(0xffffffff, warpSum, offset);\n",
        "\t}\n",
        "\n",
        "\tif(threadIndex % warpSize == 0){sharedMemory[threadIndex / warpSize] = warpSum;}\n",
        "\t__syncthreads();\n",
        "\t// block-level sum\n",
        "\tif(threadIndex < warpSize)\n",
        "\t{\n",
        "\t\tint warpCount = CEIL_DIV(blockDim.x, warpSize);\n",
        "\t\tfloat v = (threadIndex < warpCount) ? sharedMemory[threadIndex] : 0.0f;\n",
        "\t\tfor(int offset = warpSize / 2; offset > 0; offset /= 2)\n",
        "\t\t{\n",
        "\t\t\tv += __shfl_down_sync(0xffffffff, v, offset);\n",
        "\t\t}\n",
        "\n",
        "\t\tif(threadIndex == 0){sharedMemory[0] = v;}\n",
        "\t}\n",
        "\t__syncthreads();\n",
        "\tfloat rowNormalizer = sharedMemory[0];\n",
        "\t__syncthreads();\n",
        "\tfor(int i = threadIndex; i < cols; i += blockDim.x)\n",
        "\t{\n",
        "      \t\toutputRow[i] = expf(inputRow[i] - rowMaximum) / rowNormalizer;\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void BasicSoftmaxCPU(int rows, int cols, float *input, float *output)\n",
        "{\n",
        "\tclock_t start = clock();\n",
        "\tfor (int r = 0; r < rows; r++)\n",
        "\t{\n",
        "\t\tfloat *row = input + r*cols;\n",
        "\t\tfloat *out = output + r*cols;\n",
        "\t\tfloat rowMax = -INFINITY;\n",
        "\t\tfor(int c = 0; c < cols; c++)if (row[c] > rowMax) rowMax = row[c];\n",
        "\n",
        "\t\tfloat sum = 0.0f;\n",
        "\t\tfor (int c = 0; c < cols; c++)\n",
        "\t\t{\n",
        "\t\t\tout[c] = expf(row[c] - rowMax);\n",
        "\t\t\tsum += out[c];\n",
        "\t\t}\n",
        "\t\tfor(int c = 0; c < cols; c++)out[c] /= sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint rows = 2048;     //matrixRows\n",
        "\tint cols = 1024;      //matrixColumns\n",
        "\tint BLOCK = 256;  //threads per block\n",
        "\n",
        "\tsize_t bytes = rows * cols * sizeof(float);\n",
        "\n",
        "\tfloat *inputMatrix  = (float*)malloc(bytes);\n",
        "\tfloat *outputMatrixGPU = (float*)malloc(bytes);\n",
        "\tfloat *outputMatrixCPU    = (float*)malloc(bytes);\n",
        "\n",
        "\tsrand((unsigned)time(NULL));\n",
        "\tfor(int i = 0; i < rows*cols; i++){inputMatrix[i] = ((float)rand() / RAND_MAX) * 5.0f - 2.5f;}\n",
        "\n",
        "\tfloat *gpuCopyInput, *gpuCopyOutput;\n",
        "\tCUDA_CHECK(cudaMalloc(&gpuCopyInput, bytes));\n",
        "\tCUDA_CHECK(cudaMalloc(&gpuCopyOutput, bytes));\n",
        "\tCUDA_CHECK(cudaMemcpy(gpuCopyInput, inputMatrix, bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "\t/*Time GPU code*/\n",
        "\tcudaEvent_t start, stop;\n",
        "\tCUDA_CHECK(cudaEventCreate(&start));\n",
        "\tCUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "\tdim3 grid(rows);\n",
        "\tdim3 block(BLOCK);\n",
        "\n",
        "\tCUDA_CHECK(cudaEventRecord(start));\n",
        "\tOnlineSoftmaxCUDA<<<grid, block>>>(rows, cols, gpuCopyInput, gpuCopyOutput);\n",
        "\tCUDA_CHECK(cudaEventRecord(stop));\n",
        "\tCUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "\tfloat gpuTimeMs = 0.f;\n",
        "\tCUDA_CHECK(cudaEventElapsedTime(&gpuTimeMs, start, stop));\n",
        "\n",
        "\tCUDA_CHECK(cudaMemcpy(outputMatrixGPU, gpuCopyOutput, bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "\t/*Time CPU code*/\n",
        "\tclock_t cpu_start = clock();\n",
        "\tBasicSoftmaxCPU(rows, cols, inputMatrix, outputMatrixCPU);\n",
        "\tclock_t cpu_end = clock();\n",
        "\tfloat cpuTimeMs = 1000.0f * (cpu_end - cpu_start) / CLOCKS_PER_SEC;\n",
        "\n",
        "\t/*Compare accuracy*/\n",
        "\n",
        "\tfloat maxError = 0.0f;\n",
        "\tfor (int i = 0; i < rows*cols; i++)\n",
        "\t{\n",
        "\t\tfloat err = fabs(outputMatrixGPU[i] - outputMatrixCPU[i]);\n",
        "\t\tif(err > maxError) maxError = err;\n",
        "\t}\n",
        "\n",
        "\tprintf(\"GPU softmax time: %.3f ms\\n\", gpuTimeMs);\n",
        "\tprintf(\"CPU softmax time: %.3f ms\\n\", cpuTimeMs);\n",
        "\tprintf(\"Max absolute error: %e\\n\", maxError);\n",
        "\n",
        "\t/*Cleanup*/\n",
        "\tfree(inputMatrix); free(outputMatrixGPU); free(outputMatrixCPU);\n",
        "\tCUDA_CHECK(cudaFree(gpuCopyInput));\n",
        "\tCUDA_CHECK(cudaFree(gpuCopyOutput));\n",
        "\n",
        "\tCUDA_CHECK(cudaEventDestroy(start));\n",
        "\tCUDA_CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ]
    }
  ]
}